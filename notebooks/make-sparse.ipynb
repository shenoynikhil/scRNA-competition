{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f0268c5",
   "metadata": {},
   "source": [
    "### Inspired by <a href=\"https://github.com/shu65/open-problems-multimodal/blob/main/script/make_compressed_dataset.py\">Code</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ea27e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f584fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_parquet(filename, out_filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df.to_parquet(out_filename + \".parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "942a5c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_h5_to_sparse_csr(filename, out_filename, chunksize=2500):\n",
    "    start = 0\n",
    "    total_rows = 0\n",
    "\n",
    "    sparse_chunks_data_list = []\n",
    "    chunks_index_list = []\n",
    "    columns_name = None\n",
    "    while True:\n",
    "        df_chunk = pd.read_hdf(filename, start=start, stop=start + chunksize)\n",
    "        if len(df_chunk) == 0:\n",
    "            break\n",
    "        chunk_data_as_sparse = scipy.sparse.csr_matrix(df_chunk.to_numpy())\n",
    "        sparse_chunks_data_list.append(chunk_data_as_sparse)\n",
    "        chunks_index_list.append(df_chunk.index.to_numpy())\n",
    "\n",
    "        if columns_name is None:\n",
    "            columns_name = df_chunk.columns.to_numpy()\n",
    "        else:\n",
    "            assert np.all(columns_name == df_chunk.columns.to_numpy())\n",
    "\n",
    "        total_rows += len(df_chunk)\n",
    "        print(total_rows)\n",
    "        if len(df_chunk) < chunksize:\n",
    "            del df_chunk\n",
    "            break\n",
    "        del df_chunk\n",
    "        start += chunksize\n",
    "\n",
    "    all_data_sparse = scipy.sparse.vstack(sparse_chunks_data_list)\n",
    "    del sparse_chunks_data_list\n",
    "\n",
    "    all_indices = np.hstack(chunks_index_list)\n",
    "\n",
    "    scipy.sparse.save_npz(out_filename + \"_values.sparse\", all_data_sparse)\n",
    "    np.savez(out_filename + \"_idxcol.npz\", index=all_indices, columns=columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8cbcc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(data_dir, output_data_dir):\n",
    "    if output_data_dir is None:\n",
    "        output_data_dir = data_dir\n",
    "    \n",
    "    # make sure you have write access\n",
    "    os.makedirs(output_data_dir, exist_ok=True)\n",
    "    file_prefixes = [\"evaluation_ids\", \"metadata\", \"sample_submission\"]\n",
    "    for file_prefix in file_prefixes:\n",
    "        convert_to_parquet(os.path.join(data_dir, f\"{file_prefix}.csv\"), os.path.join(output_data_dir, file_prefix))\n",
    "    file_prefixes = [\n",
    "        \"test_cite_inputs\",\n",
    "        \"test_multi_inputs\",\n",
    "        \"train_cite_inputs\",\n",
    "        \"train_cite_targets\",\n",
    "        \"train_multi_inputs\",\n",
    "        \"train_multi_targets\",\n",
    "    ]\n",
    "    for file_prefix in file_prefixes:\n",
    "        convert_h5_to_sparse_csr(os.path.join(data_dir, f\"{file_prefix}.h5\"), os.path.join(output_data_dir, file_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0a3432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/arc/project/st-jiaruid-1/yinian/multiome/'\n",
    "output_data_dir = '/scratch/st-jiaruid-1/shenoy/data/multiome-sparse-rc/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e42c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "5000\n",
      "7500\n",
      "10000\n",
      "12500\n",
      "15000\n",
      "17500\n",
      "20000\n",
      "22500\n",
      "25000\n",
      "27500\n",
      "30000\n",
      "32500\n",
      "35000\n",
      "37500\n",
      "40000\n",
      "42500\n",
      "45000\n",
      "47500\n",
      "48663\n",
      "2500\n",
      "5000\n",
      "7500\n",
      "10000\n",
      "12500\n",
      "15000\n",
      "17500\n",
      "20000\n",
      "22500\n",
      "25000\n",
      "27500\n",
      "30000\n",
      "32500\n",
      "35000\n",
      "37500\n",
      "40000\n",
      "42500\n",
      "45000\n",
      "47500\n",
      "50000\n",
      "52500\n",
      "55000\n",
      "55935\n",
      "2500\n",
      "5000\n",
      "7500\n",
      "10000\n",
      "12500\n",
      "15000\n",
      "17500\n",
      "20000\n",
      "22500\n",
      "25000\n",
      "27500\n",
      "30000\n",
      "32500\n",
      "35000\n",
      "37500\n",
      "40000\n",
      "42500\n",
      "45000\n",
      "47500\n",
      "50000\n",
      "52500\n",
      "55000\n",
      "57500\n",
      "60000\n",
      "62500\n",
      "65000\n",
      "67500\n",
      "70000\n"
     ]
    }
   ],
   "source": [
    "compress(data_dir, output_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e7f018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
