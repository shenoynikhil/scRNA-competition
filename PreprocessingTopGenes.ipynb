{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3424ecb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/pbs.4256786.pbsha.ib.sockeye/matplotlib-6hpjxl09 because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[ 'NUMBA_CACHE_DIR' ] = '/scratch/st-jiaruid-1/yinian/tmp/' # https://github.com/scverse/scanpy/issues/2113\n",
    "\n",
    "import logging\n",
    "import anndata as ad\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy\n",
    "\n",
    "import h5py\n",
    "import hdf5plugin\n",
    "import tables\n",
    "\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fd9376",
   "metadata": {},
   "source": [
    "### Preprocessing hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf02850",
   "metadata": {},
   "outputs": [],
   "source": [
    "CITE_TOP_GENES = 250\n",
    "MULTI_TOP_GENES = 1000\n",
    "CITE_STACK = 10\n",
    "MULTI_STACK = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0932b165",
   "metadata": {},
   "source": [
    "### Load the CITE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fafb4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/arc/project/st-jiaruid-1/yinian/multiome/\"\n",
    "FP_CELL_METADATA = os.path.join(DATA_DIR,\"metadata.csv\")\n",
    "\n",
    "FP_CITE_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_cite_inputs.h5\")\n",
    "FP_CITE_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_cite_targets.h5\")\n",
    "FP_CITE_TEST_INPUTS = os.path.join(DATA_DIR,\"test_cite_inputs.h5\")\n",
    "\n",
    "FP_MULTIOME_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_multi_inputs.h5\")\n",
    "FP_MULTIOME_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_multi_targets.h5\")\n",
    "FP_MULTIOME_TEST_INPUTS = os.path.join(DATA_DIR,\"test_multi_inputs.h5\")\n",
    "\n",
    "FP_SUBMISSION = os.path.join(DATA_DIR,\"sample_submission.csv\")\n",
    "FP_EVALUATION_IDS = os.path.join(DATA_DIR,\"evaluation_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76521ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(FP_CELL_METADATA)\n",
    "metadata_df = metadata_df.set_index('cell_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e15d1d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/arc/project/st-jiaruid-1/yinian/multiome/'\n",
    "filenames = [\n",
    "    'test_cite_inputs', \n",
    "#     'test_multi_inputs', \n",
    "    'train_cite_inputs',\n",
    "    'train_cite_targets',\n",
    "#     'train_multi_inputs',\n",
    "#     'train_multi_targets',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdb8e79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test_cite_inputs.h5\n",
      "loading train_cite_inputs.h5\n",
      "loading train_cite_targets.h5\n"
     ]
    }
   ],
   "source": [
    "adatas = {}\n",
    "chunk_size = 10000\n",
    "\n",
    "for filename in filenames:\n",
    "    print(f'loading {filename}.h5')\n",
    "    filepath = base_dir + filename + '.h5'\n",
    "    \n",
    "    h5_file = h5py.File(filepath)\n",
    "    h5_data = h5_file[filename]\n",
    "    \n",
    "    features = h5_data['axis0'][:]\n",
    "    cell_ids = h5_data['axis1'][:]\n",
    "    \n",
    "    features = features.astype(str)\n",
    "    cell_ids = cell_ids.astype(str)\n",
    "    \n",
    "    technology = metadata_df.loc[cell_ids, 'technology'].unique().item()\n",
    "    \n",
    "\n",
    "    sparse_chunks = []\n",
    "    n_cells = h5_data['block0_values'].shape[0]\n",
    "\n",
    "    for chunk_indices in np.array_split(np.arange(n_cells), 100):\n",
    "        chunk = h5_data['block0_values'][chunk_indices]\n",
    "        sparse_chunk = scipy.sparse.csr_matrix(chunk)\n",
    "        sparse_chunks.append(sparse_chunk)\n",
    "\n",
    "    X = scipy.sparse.vstack(sparse_chunks)\n",
    "\n",
    "    adata = ad.AnnData(\n",
    "        X=X,\n",
    "        obs=metadata_df.loc[cell_ids],\n",
    "        var=pd.DataFrame(index=features),\n",
    "    )\n",
    "    \n",
    "    adatas[filename] = adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ae72a5",
   "metadata": {},
   "source": [
    "### CITE top genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a3bc242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gex_de_analysis(adata_GEX, top_genes):\n",
    "    '''get top DE genes per cell type (multiome)'''\n",
    "#     adata_GEX = sc.read_h5ad(path)\n",
    "#     adata_GEX.X = adata_GEX.layers['counts']\n",
    "#     sc.pp.normalize_per_cell(adata_GEX, counts_per_cell_after=1e6)\n",
    "#     sc.pp.log1p(adata_GEX)\n",
    "    sc.pp.filter_cells(adata_GEX, min_genes=200)\n",
    "    sc.pp.filter_genes(adata_GEX, min_cells=3)\n",
    "    adata_GEX.var['mt'] = adata_GEX.var_names.str.contains('MT-') \n",
    "    sc.pp.calculate_qc_metrics(adata_GEX, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "    adata_GEX = adata_GEX[adata_GEX.obs.n_genes_by_counts < 4000, :]\n",
    "    sc.pp.normalize_total(adata_GEX, target_sum=1e4)\n",
    "    sc.pp.log1p(adata_GEX)\n",
    "    sc.pp.highly_variable_genes(adata_GEX, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "    sc.pp.scale(adata_GEX, max_value=10)\n",
    "    sc.tl.rank_genes_groups(adata_GEX, 'cell_type', method='wilcoxon')\n",
    "    cell_types = adata_GEX.obs.cell_type.value_counts().index\n",
    "    column_names = ['names', 'scores', 'logfoldchanges', 'pvals', 'pvals_adj', 'cell_type']\n",
    "    df = pd.DataFrame(columns = column_names)\n",
    "    for cell_type in cell_types:\n",
    "        dedf = sc.get.rank_genes_groups_df(adata_GEX, group=cell_type)\n",
    "        dedf['cell_type'] = cell_type\n",
    "        dedf = dedf.sort_values('scores', ascending=False).iloc[:top_genes]\n",
    "        df = df.append(dedf, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e64f63f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_cols = ['ENSG00000114013_CD86', 'ENSG00000120217_CD274', 'ENSG00000196776_CD47', 'ENSG00000117091_CD48', 'ENSG00000101017_CD40', 'ENSG00000102245_CD40LG', 'ENSG00000169442_CD52', 'ENSG00000117528_ABCD3', 'ENSG00000168014_C2CD3', 'ENSG00000167851_CD300A', 'ENSG00000167850_CD300C', 'ENSG00000186407_CD300E', 'ENSG00000178789_CD300LB', 'ENSG00000186074_CD300LF', 'ENSG00000241399_CD302', 'ENSG00000167775_CD320', 'ENSG00000105383_CD33', 'ENSG00000174059_CD34', 'ENSG00000135218_CD36', 'ENSG00000104894_CD37', 'ENSG00000004468_CD38', 'ENSG00000167286_CD3D', 'ENSG00000198851_CD3E', 'ENSG00000117877_CD3EAP', 'ENSG00000074696_HACD3', 'ENSG00000015676_NUDCD3', 'ENSG00000161714_PLCD3', 'ENSG00000132300_PTCD3', 'ENSG00000082014_SMARCD3', 'ENSG00000121594_CD80', 'ENSG00000110651_CD81', 'ENSG00000238184_CD81-AS1', 'ENSG00000085117_CD82', 'ENSG00000112149_CD83', 'ENSG00000066294_CD84', 'ENSG00000114013_CD86', 'ENSG00000172116_CD8B', 'ENSG00000254126_CD8B2', 'ENSG00000177455_CD19', 'ENSG00000105383_CD33', 'ENSG00000173762_CD7', 'ENSG00000125726_CD70', 'ENSG00000137101_CD72', 'ENSG00000019582_CD74', 'ENSG00000105369_CD79A', 'ENSG00000007312_CD79B', 'ENSG00000090470_PDCD7', 'ENSG00000119688_ABCD4', 'ENSG00000010610_CD4', 'ENSG00000101017_CD40', 'ENSG00000102245_CD40LG', 'ENSG00000026508_CD44', 'ENSG00000117335_CD46', 'ENSG00000196776_CD47', 'ENSG00000117091_CD48', 'ENSG00000188921_HACD4', 'ENSG00000150593_PDCD4', 'ENSG00000203497_PDCD4-AS1', 'ENSG00000115556_PLCD4', 'ENSG00000026508_CD44', 'ENSG00000170458_CD14', 'ENSG00000117281_CD160', 'ENSG00000177575_CD163', 'ENSG00000135535_CD164', 'ENSG00000091972_CD200', 'ENSG00000163606_CD200R1', 'ENSG00000206531_CD200R1L', 'ENSG00000182685_BRICD5', 'ENSG00000111731_C2CD5', 'ENSG00000169442_CD52', 'ENSG00000143119_CD53', 'ENSG00000196352_CD55', 'ENSG00000116815_CD58', 'ENSG00000085063_CD59', 'ENSG00000105185_PDCD5', 'ENSG00000255909_PDCD5P1', 'ENSG00000145284_SCD5', 'ENSG00000167775_CD320', 'ENSG00000110848_CD69', 'ENSG00000139187_KLRG1', 'ENSG00000139193_CD27', 'ENSG00000215039_CD27-AS1', 'ENSG00000120217_CD274', 'ENSG00000103855_CD276', 'ENSG00000204287_HLA-DRA', 'ENSG00000196126_HLA-DRB1', 'ENSG00000198502_HLA-DRB5', 'ENSG00000229391_HLA-DRB6', 'ENSG00000116815_CD58', 'ENSG00000168329_CX3CR1', 'ENSG00000272398_CD24', 'ENSG00000122223_CD244', 'ENSG00000198821_CD247', 'ENSG00000122223_CD244', 'ENSG00000177575_CD163', 'ENSG00000112149_CD83', 'ENSG00000185963_BICD2', 'ENSG00000157617_C2CD2', 'ENSG00000172375_C2CD2L', 'ENSG00000116824_CD2', 'ENSG00000091972_CD200', 'ENSG00000163606_CD200R1', 'ENSG00000206531_CD200R1L', 'ENSG00000012124_CD22', 'ENSG00000150637_CD226', 'ENSG00000272398_CD24', 'ENSG00000122223_CD244', 'ENSG00000198821_CD247', 'ENSG00000139193_CD27', 'ENSG00000215039_CD27-AS1', 'ENSG00000120217_CD274', 'ENSG00000103855_CD276', 'ENSG00000198087_CD2AP', 'ENSG00000169217_CD2BP2', 'ENSG00000144554_FANCD2', 'ENSG00000206527_HACD2', 'ENSG00000170584_NUDCD2', 'ENSG00000071994_PDCD2', 'ENSG00000126249_PDCD2L', 'ENSG00000049883_PTCD2', 'ENSG00000186193_SAPCD2', 'ENSG00000108604_SMARCD2', 'ENSG00000185561_TLCD2', 'ENSG00000075035_WSCD2', 'ENSG00000150637_CD226', 'ENSG00000110651_CD81', 'ENSG00000238184_CD81-AS1', 'ENSG00000134061_CD180', 'ENSG00000004468_CD38', 'ENSG00000012124_CD22', 'ENSG00000150637_CD226', 'ENSG00000135404_CD63', 'ENSG00000135218_CD36', 'ENSG00000137101_CD72', 'ENSG00000125810_CD93', 'ENSG00000010278_CD9', 'ENSG00000125810_CD93', 'ENSG00000153283_CD96', 'ENSG00000002586_CD99', 'ENSG00000102181_CD99L2', 'ENSG00000223773_CD99P1', 'ENSG00000204592_HLA-E', 'ENSG00000085117_CD82', 'ENSG00000134256_CD101']\n",
    "important_cols = set(important_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4200d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = adatas['train_cite_inputs']\n",
    "x_test = adatas['train_cite_inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dcf1d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/arc/project/st-jiaruid-1/yinian/tensorflow-gpu/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:155: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "/arc/project/st-jiaruid-1/yinian/tensorflow-gpu/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:420: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, 'logfoldchanges'] = np.log2(\n",
      "/arc/project/st-jiaruid-1/yinian/tensorflow-gpu/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:420: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, 'logfoldchanges'] = np.log2(\n",
      "/arc/project/st-jiaruid-1/yinian/tensorflow-gpu/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:420: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, 'logfoldchanges'] = np.log2(\n",
      "/arc/project/st-jiaruid-1/yinian/tensorflow-gpu/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:420: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, 'logfoldchanges'] = np.log2(\n",
      "/arc/project/st-jiaruid-1/yinian/tensorflow-gpu/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:420: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, 'logfoldchanges'] = np.log2(\n",
      "/arc/project/st-jiaruid-1/yinian/tensorflow-gpu/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:420: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, 'logfoldchanges'] = np.log2(\n",
      "/arc/project/st-jiaruid-1/yinian/tensorflow-gpu/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:420: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, 'logfoldchanges'] = np.log2(\n",
      "/tmp/pbs.4256707.pbsha.ib.sockeye/ipykernel_175380/2826204671.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(dedf, ignore_index=True)\n",
      "/tmp/pbs.4256707.pbsha.ib.sockeye/ipykernel_175380/2826204671.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(dedf, ignore_index=True)\n",
      "/tmp/pbs.4256707.pbsha.ib.sockeye/ipykernel_175380/2826204671.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(dedf, ignore_index=True)\n",
      "/tmp/pbs.4256707.pbsha.ib.sockeye/ipykernel_175380/2826204671.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(dedf, ignore_index=True)\n",
      "/tmp/pbs.4256707.pbsha.ib.sockeye/ipykernel_175380/2826204671.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(dedf, ignore_index=True)\n",
      "/tmp/pbs.4256707.pbsha.ib.sockeye/ipykernel_175380/2826204671.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(dedf, ignore_index=True)\n",
      "/tmp/pbs.4256707.pbsha.ib.sockeye/ipykernel_175380/2826204671.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(dedf, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "genes = gex_de_analysis(x_train.copy(), CITE_TOP_GENES)\n",
    "selected_genes = set(genes.names).union(important_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22e59d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = selected_genes.intersection(x_train.var_names)\n",
    "x_train = x_train[:, list(subset)]\n",
    "x_test = x_test[:, list(subset)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bbd215",
   "metadata": {},
   "source": [
    "### CITE stack summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0d59b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pbs.4256707.pbsha.ib.sockeye/ipykernel_175380/1797211525.py:2: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  x_train.obs[\"batch_median\"] = 0\n",
      "/tmp/pbs.4256707.pbsha.ib.sockeye/ipykernel_175380/1797211525.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_train.obs[\"batch_median\"][x_train.obs.donor == batch] = np.median(\n",
      "/tmp/pbs.4256707.pbsha.ib.sockeye/ipykernel_175380/1797211525.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_train.obs[\"batch_sd\"][x_train.obs.donor == batch] = np.std(\n",
      "/tmp/pbs.4256707.pbsha.ib.sockeye/ipykernel_175380/1797211525.py:13: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  x_test.obs[\"batch_median\"] = 0\n",
      "/tmp/pbs.4256707.pbsha.ib.sockeye/ipykernel_175380/1797211525.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_test.obs[\"batch_median\"][x_test.obs.donor == batch] = np.median(\n",
      "/tmp/pbs.4256707.pbsha.ib.sockeye/ipykernel_175380/1797211525.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_test.obs[\"batch_sd\"][x_test.obs.donor == batch] = np.std(\n"
     ]
    }
   ],
   "source": [
    "train_total = np.sum(x_train.X.toarray(), axis=1)\n",
    "test_total = np.sum(x_test.X.toarray(), axis=1)\n",
    "\n",
    "train_batches = set(x_train.obs.donor)\n",
    "x_train.obs[\"batch_median\"] = 0\n",
    "x_train.obs[\"batch_sd\"] = 0\n",
    "for batch in train_batches:\n",
    "    x_train.obs[\"batch_median\"][x_train.obs.donor == batch] = np.median(\n",
    "        train_total[x_train.obs.donor == batch]\n",
    "    )\n",
    "    x_train.obs[\"batch_sd\"][x_train.obs.donor == batch] = np.std(\n",
    "        train_total[x_train.obs.donor == batch]\n",
    "    )\n",
    "\n",
    "test_batches = set(x_test.obs.donor)\n",
    "x_test.obs[\"batch_median\"] = 0\n",
    "x_test.obs[\"batch_sd\"] = 0\n",
    "\n",
    "for batch in test_batches:\n",
    "    x_test.obs[\"batch_median\"][x_test.obs.donor == batch] = np.median(\n",
    "        test_total[x_test.obs.donor == batch]\n",
    "    )\n",
    "    x_test.obs[\"batch_sd\"][x_test.obs.donor == batch] = np.std(\n",
    "        test_total[x_test.obs.donor == batch]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb584e61",
   "metadata": {},
   "source": [
    "### Stack the summary stats on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae86ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_median = x_train.obs[\"batch_median\"]\n",
    "train_batch_sd = x_train.obs[\"batch_sd\"]\n",
    "test_batch_median = x_test.obs[\"batch_median\"]\n",
    "test_batch_sd = x_test.obs[\"batch_sd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69ddb713",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.X.toarray()\n",
    "x_test = x_test.X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e949c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(CITE_STACK):\n",
    "    x_train = np.column_stack((x_train, train_total))\n",
    "for i in range(CITE_STACK):\n",
    "    x_train = np.column_stack((x_train, train_batch_median))\n",
    "for i in range(CITE_STACK):\n",
    "    x_train = np.column_stack((x_train, train_batch_sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "383c10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(CITE_STACK):\n",
    "    x_test = np.column_stack((x_test, test_total))\n",
    "for i in range(CITE_STACK):\n",
    "    x_test = np.column_stack((x_test, test_batch_median))\n",
    "for i in range(CITE_STACK):\n",
    "    x_test = np.column_stack((x_test, test_batch_sd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25843749",
   "metadata": {},
   "source": [
    "### Normalize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "69be4cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.T\n",
    "means = np.mean(x_train, axis = 1)\n",
    "sds = np.std(x_train, axis = 1)\n",
    "means = means.reshape(len(means), 1)\n",
    "sds = sds.reshape(len(sds), 1)\n",
    "info = {\"means\":means,\"sds\":sds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee223ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - means) / sds\n",
    "x_train = x_train.T\n",
    "\n",
    "x_test = x_test.T\n",
    "x_test = (x_test - info[\"means\"]) / info[\"sds\"]\n",
    "x_test = x_test.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd8847",
   "metadata": {},
   "source": [
    "### Dump the pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "364da5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cite_train_filename = '/scratch/st-jiaruid-1/yinian/temp/top-genes-cite-train.pkl'\n",
    "cite_test_filename = '/scratch/st-jiaruid-1/yinian/temp/top-genes-cite-test.pkl'\n",
    "with open(cite_train_filename, 'wb') as f:\n",
    "    pickle.dump(x_train, f)\n",
    "with open(cite_test_filename, 'wb') as f:\n",
    "    pickle.dump(x_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2c9248",
   "metadata": {},
   "source": [
    "### Repeat for Multiome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3b06df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/arc/project/st-jiaruid-1/yinian/multiome/'\n",
    "filenames = [\n",
    "#     'test_cite_inputs', \n",
    "    'test_multi_inputs', \n",
    "#     'train_cite_inputs',\n",
    "#     'train_cite_targets',\n",
    "    'train_multi_inputs',\n",
    "    'train_multi_targets',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91b68c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test_multi_inputs.h5\n",
      "loading train_multi_inputs.h5\n",
      "loading train_multi_targets.h5\n"
     ]
    }
   ],
   "source": [
    "adatas = {}\n",
    "chunk_size = 10000\n",
    "\n",
    "for filename in filenames:\n",
    "    print(f'loading {filename}.h5')\n",
    "    filepath = base_dir + filename + '.h5'\n",
    "    \n",
    "    h5_file = h5py.File(filepath)\n",
    "    h5_data = h5_file[filename]\n",
    "    \n",
    "    features = h5_data['axis0'][:]\n",
    "    cell_ids = h5_data['axis1'][:]\n",
    "    \n",
    "    features = features.astype(str)\n",
    "    cell_ids = cell_ids.astype(str)\n",
    "    \n",
    "    technology = metadata_df.loc[cell_ids, 'technology'].unique().item()\n",
    "    \n",
    "\n",
    "    sparse_chunks = []\n",
    "    n_cells = h5_data['block0_values'].shape[0]\n",
    "\n",
    "    for chunk_indices in np.array_split(np.arange(n_cells), 100):\n",
    "        chunk = h5_data['block0_values'][chunk_indices]\n",
    "        sparse_chunk = scipy.sparse.csr_matrix(chunk)\n",
    "        sparse_chunks.append(sparse_chunk)\n",
    "\n",
    "    X = scipy.sparse.vstack(sparse_chunks)\n",
    "\n",
    "    adata = ad.AnnData(\n",
    "        X=X,\n",
    "        obs=metadata_df.loc[cell_ids],\n",
    "        var=pd.DataFrame(index=features),\n",
    "    )\n",
    "    \n",
    "    adatas[filename] = adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32687939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atac_de_analysis(adata, top_genes):\n",
    "    '''get top DA peaks per cell type'''\n",
    "    adata.X = binarize(adata.X)\n",
    "    sc.tl.rank_genes_groups(adata, 'cell_type', method='t-test')\n",
    "    cell_types = adata.obs.cell_type.value_counts().index\n",
    "    column_names = ['names', 'scores', 'logfoldchanges', 'pvals', 'pvals_adj', 'cell_type']\n",
    "    df = pd.DataFrame(columns = column_names)\n",
    "    for cell_type in cell_types:\n",
    "        dedf = sc.get.rank_genes_groups_df(adata, group=cell_type)\n",
    "        dedf['cell_type'] = cell_type\n",
    "        dedf = dedf.sort_values('scores', ascending=False).iloc[:top_genes]\n",
    "        df = df.append(dedf, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61dd99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = adatas['train_multi_inputs']\n",
    "x_test = adatas['train_multi_inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5783441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pbs.4256786.pbsha.ib.sockeye/ipykernel_178248/3608267309.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(dedf, ignore_index=True)\n",
      "/tmp/pbs.4256786.pbsha.ib.sockeye/ipykernel_178248/3608267309.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(dedf, ignore_index=True)\n",
      "/tmp/pbs.4256786.pbsha.ib.sockeye/ipykernel_178248/3608267309.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(dedf, ignore_index=True)\n",
      "/tmp/pbs.4256786.pbsha.ib.sockeye/ipykernel_178248/3608267309.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(dedf, ignore_index=True)\n",
      "/tmp/pbs.4256786.pbsha.ib.sockeye/ipykernel_178248/3608267309.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(dedf, ignore_index=True)\n",
      "/tmp/pbs.4256786.pbsha.ib.sockeye/ipykernel_178248/3608267309.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(dedf, ignore_index=True)\n",
      "/tmp/pbs.4256786.pbsha.ib.sockeye/ipykernel_178248/3608267309.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(dedf, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "genes = atac_de_analysis(x_train.copy(), MULTI_TOP_GENES)\n",
    "selected_genes = set(genes.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8e5ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = selected_genes.intersection(x_train.var_names)\n",
    "x_train = x_train[:, list(subset)]\n",
    "x_test = x_test[:, list(subset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "258d049b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pbs.4256786.pbsha.ib.sockeye/ipykernel_178248/1108718924.py:5: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  x_train.obs[\"batch_median\"] = 0\n",
      "/tmp/pbs.4256786.pbsha.ib.sockeye/ipykernel_178248/1108718924.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_train.obs[\"batch_median\"][x_train.obs.donor == batch] = np.median(\n",
      "/tmp/pbs.4256786.pbsha.ib.sockeye/ipykernel_178248/1108718924.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_train.obs[\"batch_sd\"][x_train.obs.donor == batch] = np.std(\n",
      "/tmp/pbs.4256786.pbsha.ib.sockeye/ipykernel_178248/1108718924.py:16: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  x_test.obs[\"batch_median\"] = 0\n",
      "/tmp/pbs.4256786.pbsha.ib.sockeye/ipykernel_178248/1108718924.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_test.obs[\"batch_median\"][x_test.obs.donor == batch] = np.median(\n",
      "/tmp/pbs.4256786.pbsha.ib.sockeye/ipykernel_178248/1108718924.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_test.obs[\"batch_sd\"][x_test.obs.donor == batch] = np.std(\n"
     ]
    }
   ],
   "source": [
    "train_total = np.sum(x_train.X.toarray(), axis=1)\n",
    "test_total = np.sum(x_test.X.toarray(), axis=1)\n",
    "\n",
    "train_batches = set(x_train.obs.donor)\n",
    "x_train.obs[\"batch_median\"] = 0\n",
    "x_train.obs[\"batch_sd\"] = 0\n",
    "for batch in train_batches:\n",
    "    x_train.obs[\"batch_median\"][x_train.obs.donor == batch] = np.median(\n",
    "        train_total[x_train.obs.donor == batch]\n",
    "    )\n",
    "    x_train.obs[\"batch_sd\"][x_train.obs.donor == batch] = np.std(\n",
    "        train_total[x_train.obs.donor == batch]\n",
    "    )\n",
    "\n",
    "test_batches = set(x_test.obs.donor)\n",
    "x_test.obs[\"batch_median\"] = 0\n",
    "x_test.obs[\"batch_sd\"] = 0\n",
    "\n",
    "for batch in test_batches:\n",
    "    x_test.obs[\"batch_median\"][x_test.obs.donor == batch] = np.median(\n",
    "        test_total[x_test.obs.donor == batch]\n",
    "    )\n",
    "    x_test.obs[\"batch_sd\"][x_test.obs.donor == batch] = np.std(\n",
    "        test_total[x_test.obs.donor == batch]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00357453",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_median = x_train.obs[\"batch_median\"]\n",
    "train_batch_sd = x_train.obs[\"batch_sd\"]\n",
    "test_batch_median = x_test.obs[\"batch_median\"]\n",
    "test_batch_sd = x_test.obs[\"batch_sd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75aa3a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.X.toarray()\n",
    "x_test = x_test.X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4524bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(MULTI_STACK):\n",
    "    x_train = np.column_stack((x_train, train_total))\n",
    "for i in range(MULTI_STACK):\n",
    "    x_train = np.column_stack((x_train, train_batch_median))\n",
    "for i in range(MULTI_STACK):\n",
    "    x_train = np.column_stack((x_train, train_batch_sd))\n",
    "\n",
    "for i in range(MULTI_STACK):\n",
    "    x_test = np.column_stack((x_test, test_total))\n",
    "for i in range(MULTI_STACK):\n",
    "    x_test = np.column_stack((x_test, test_batch_median))\n",
    "for i in range(MULTI_STACK):\n",
    "    x_test = np.column_stack((x_test, test_batch_sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8f3c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.T\n",
    "means = np.mean(x_train, axis = 1)\n",
    "sds = np.std(x_train, axis = 1)\n",
    "means = means.reshape(len(means), 1)\n",
    "sds = sds.reshape(len(sds), 1)\n",
    "info = {\"means\":means,\"sds\":sds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f2078bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - means) / sds\n",
    "x_train = x_train.T\n",
    "\n",
    "x_test = x_test.T\n",
    "x_test = (x_test - info[\"means\"]) / info[\"sds\"]\n",
    "x_test = x_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f12f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "cite_train_filename = '/scratch/st-jiaruid-1/yinian/temp/top-genes-multi-train.pkl'\n",
    "cite_test_filename = '/scratch/st-jiaruid-1/yinian/temp/top-genes-multi-test.pkl'\n",
    "with open(cite_train_filename, 'wb') as f:\n",
    "    pickle.dump(x_train, f)\n",
    "with open(cite_test_filename, 'wb') as f:\n",
    "    pickle.dump(x_test, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
